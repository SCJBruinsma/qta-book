<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="9.1 Latent Dirichlet Allocation | Quantitative Text Analysis" />
<meta property="og:type" content="book" />


<meta property="og:description" content="Theory and Methods for Quantitative Text Analysis" />


<meta name="author" content="Kostas Gemenis &amp; Bastiaan Bruinsma" />

<meta name="date" content="2021-07-28" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="Theory and Methods for Quantitative Text Analysis">

<title>9.1 Latent Dirichlet Allocation | Quantitative Text Analysis</title>

<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-background.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<script src="libs/jquery-3.5.1/jquery.min.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.18/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 2em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#welcome">Welcome!</a></li>
<li><a href="1-getting-started.html#getting-started"><span class="toc-section-number">1</span> Getting Started</a>
<ul>
<li><a href="1-1-r-on-windows.html#r-on-windows"><span class="toc-section-number">1.1</span> R on Windows</a></li>
<li><a href="1-2-r-on-linux.html#r-on-linux"><span class="toc-section-number">1.2</span> R on Linux</a></li>
<li><a href="1-3-r-on-macos.html#r-on-macos"><span class="toc-section-number">1.3</span> R on macOS</a></li>
<li><a href="1-4-r-in-the-cloud.html#r-in-the-cloud"><span class="toc-section-number">1.4</span> R in the Cloud</a></li>
</ul></li>
<li><a href="2-installing-packages.html#installing-packages"><span class="toc-section-number">2</span> Installing Packages</a>
<ul>
<li><a href="2-1-installing-from-cran.html#installing-from-cran"><span class="toc-section-number">2.1</span> Installing from CRAN</a></li>
<li><a href="2-2-installing-from-github.html#installing-from-github"><span class="toc-section-number">2.2</span> Installing from GitHub</a></li>
<li><a href="2-3-packages-for-quantitative-text-analysis-in-r.html#packages-for-quantitative-text-analysis-in-r"><span class="toc-section-number">2.3</span> Packages for Quantitative Text Analysis in R</a></li>
<li><a href="2-4-issues-bugs-and-errors.html#issues-bugs-and-errors"><span class="toc-section-number">2.4</span> Issues, Bugs and Errors</a></li>
</ul></li>
<li><a href="3-importing-data.html#importing-data"><span class="toc-section-number">3</span> Importing Data</a>
<ul>
<li><a href="3-1-text-in-r.html#text-in-r"><span class="toc-section-number">3.1</span> Text in R</a></li>
<li><a href="3-2-import-txt-files.html#import-.txt-files"><span class="toc-section-number">3.2</span> Import .txt Files</a></li>
<li><a href="3-3-import-pdf-files.html#import-.pdf-files"><span class="toc-section-number">3.3</span> Import .pdf Files</a></li>
<li><a href="3-4-import-csv-files.html#import-.csv-files"><span class="toc-section-number">3.4</span> Import .csv Files</a></li>
<li><a href="3-5-import-from-an-api.html#import-from-an-api"><span class="toc-section-number">3.5</span> Import from an API</a></li>
<li><a href="3-6-import-using-web-scraping.html#import-using-web-scraping"><span class="toc-section-number">3.6</span> Import using Web Scraping</a></li>
</ul></li>
<li><a href="4-reliability-and-validity.html#reliability-and-validity"><span class="toc-section-number">4</span> Reliability and Validity</a>
<ul>
<li><a href="4-1-inter-coder-agreement.html#inter-coder-agreement"><span class="toc-section-number">4.1</span> Inter-Coder Agreement</a></li>
<li><a href="4-2-visualizing-quality.html#visualizing-quality"><span class="toc-section-number">4.2</span> Visualizing Quality</a></li>
</ul></li>
<li><a href="5-preliminaries.html#preliminaries"><span class="toc-section-number">5</span> Preliminaries</a>
<ul>
<li><a href="5-1-the-corpus.html#the-corpus"><span class="toc-section-number">5.1</span> The Corpus</a></li>
<li><a href="5-2-keywords-in-context.html#keywords-in-context"><span class="toc-section-number">5.2</span> Keywords in Context</a></li>
<li><a href="5-3-visualisations-and-descriptives.html#visualisations-and-descriptives"><span class="toc-section-number">5.3</span> Visualisations and Descriptives</a></li>
<li><a href="5-4-text-statistics.html#text-statistics"><span class="toc-section-number">5.4</span> Text Statistics</a></li>
</ul></li>
<li><a href="6-dictionary-analysis.html#dictionary-analysis"><span class="toc-section-number">6</span> Dictionary Analysis</a>
<ul>
<li><a href="6-1-classical-dictionary-analysis.html#classical-dictionary-analysis"><span class="toc-section-number">6.1</span> Classical Dictionary Analysis</a></li>
<li><a href="6-2-sentiment-analysis.html#sentiment-analysis"><span class="toc-section-number">6.2</span> Sentiment Analysis</a>
<ul>
<li><a href="6-2-sentiment-analysis.html#movie-reviews"><span class="toc-section-number">6.2.1</span> Movie Reviews</a></li>
<li><a href="6-2-sentiment-analysis.html#twitter"><span class="toc-section-number">6.2.2</span> Twitter</a></li>
</ul></li>
</ul></li>
<li><a href="7-scaling.html#scaling"><span class="toc-section-number">7</span> Scaling</a>
<ul>
<li><a href="7-1-wordscores.html#wordscores"><span class="toc-section-number">7.1</span> Wordscores</a></li>
<li><a href="7-2-wordfish.html#wordfish"><span class="toc-section-number">7.2</span> Wordfish</a></li>
<li><a href="7-3-correspondence-analysis.html#correspondence-analysis"><span class="toc-section-number">7.3</span> Correspondence Analysis</a></li>
</ul></li>
<li><a href="8-supervised-methods.html#supervised-methods"><span class="toc-section-number">8</span> Supervised Methods</a>
<ul>
<li><a href="8-1-support-vector-machines.html#support-vector-machines"><span class="toc-section-number">8.1</span> Support Vector Machines</a>
<ul>
<li><a href="8-1-support-vector-machines.html#svm-with-rtexttools"><span class="toc-section-number">8.1.1</span> SVM with RTextTools</a></li>
<li><a href="8-1-support-vector-machines.html#svm-with-quanteda"><span class="toc-section-number">8.1.2</span> SVM with Quanteda</a></li>
</ul></li>
<li><a href="8-2-naive-bayes.html#naive-bayes"><span class="toc-section-number">8.2</span> Naive Bayes</a></li>
</ul></li>
<li><a href="9-unsupervised-methods.html#unsupervised-methods"><span class="toc-section-number">9</span> Unsupervised Methods</a>
<ul>
<li><a href="9-1-latent-dirichlet-allocation.html#latent-dirichlet-allocation"><span class="toc-section-number">9.1</span> Latent Dirichlet Allocation</a></li>
<li><a href="9-2-seeded-latent-dirichlet-allocation.html#seeded-latent-dirichlet-allocation"><span class="toc-section-number">9.2</span> Seeded Latent Dirichlet Allocation</a></li>
<li><a href="9-3-structural-topic-model.html#structural-topic-model"><span class="toc-section-number">9.3</span> Structural Topic Model</a></li>
</ul></li>
<li><a href="10-texttricks.html#texttricks"><span class="toc-section-number">10</span> Texttricks</a></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="latent-dirichlet-allocation" class="section level2" number="9.1">
<h2><span class="header-section-number">9.1</span> Latent Dirichlet Allocation</h2>
<p>Latent Dirichlet Allocation, or LDA, relies on the idea is that each text is a mix of topics, and each word belongs to one of these. To run LDA, we will use the <code>topicmodels</code> package, and use the inaugural speeches as an example. First, we will use the <code>convert</code> function to convert the data frequency matrix to a data term matrix as this is what <code>topicmodels</code> uses:</p>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="9-1-latent-dirichlet-allocation.html#cb232-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(topicmodels)</span>
<span id="cb232-2"><a href="9-1-latent-dirichlet-allocation.html#cb232-2" aria-hidden="true" tabindex="-1"></a>inaugural_dtm <span class="ot">&lt;-</span> <span class="fu">convert</span>(data_inaugural_dfm, <span class="at">to =</span> <span class="st">&quot;topicmodels&quot;</span>)</span></code></pre></div>
<p>Then, we fit an LDA model with 10 topics. First, we have to define some a priori parameters for the model. Here, we will use the Gibbs sampling method to fit the LDA model <span class="citation">(<label for="tufte-mn-34" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-34" class="margin-toggle">Griffiths &amp; Steyvers, 2004<span class="marginnote">Griffiths, T. L., &amp; Steyvers, M. (2004). Finding scientific topics. <em>Proceedings of the National Academy of Sciences</em>, <em>101</em>(suppl 1), 5228–5235. <a href="https://doi.org/10.1073/pnas.0307752101">https://doi.org/10.1073/pnas.0307752101</a></span>)</span> over the alternative VEM approach <span class="citation">(<label for="tufte-mn-35" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-35" class="margin-toggle">Blei et al., 2003<span class="marginnote">Blei, D. M., Ng, A. Y., &amp; Jordan, M. I. (2003). Latent dirichlet allocation. <em>Journal of Machine Learning Research</em>, <em>3</em>(Jan), 993–1022.</span>)</span>. Gibbs sampling performs a random walk over the distribution so we need to set a seed to ensure reproducible results. In this particular example, we set five seeds for five independent runs. We also set a burn-in period of 2000 as the first iterations will not reflect the distribution well, and take the 200th iteration of the following 1000:</p>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="9-1-latent-dirichlet-allocation.html#cb233-1" aria-hidden="true" tabindex="-1"></a>burnin <span class="ot">&lt;-</span> <span class="dv">2000</span></span>
<span id="cb233-2"><a href="9-1-latent-dirichlet-allocation.html#cb233-2" aria-hidden="true" tabindex="-1"></a>iter <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb233-3"><a href="9-1-latent-dirichlet-allocation.html#cb233-3" aria-hidden="true" tabindex="-1"></a>thin <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb233-4"><a href="9-1-latent-dirichlet-allocation.html#cb233-4" aria-hidden="true" tabindex="-1"></a>seed <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="dv">42</span>, <span class="dv">5</span>, <span class="dv">24</span>, <span class="dv">158</span>, <span class="dv">2500</span>)</span>
<span id="cb233-5"><a href="9-1-latent-dirichlet-allocation.html#cb233-5" aria-hidden="true" tabindex="-1"></a>nstart <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb233-6"><a href="9-1-latent-dirichlet-allocation.html#cb233-6" aria-hidden="true" tabindex="-1"></a>best <span class="ot">&lt;-</span> <span class="cn">TRUE</span></span></code></pre></div>
<p>The LDA algorithm estimates topic-word probabilities as well as topic-document probabilities that we can extract and visualize. Here, we will start with the topic-word probabilities called <em>beta</em>. To do this, we will use the <code>tidytext</code> package which is part of the tidyverse family of packages. Central to the logic of tidyverse packages is that it does not rely on a document term matrix but represents the data in a long format <span class="citation">(<label for="tufte-mn-36" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-36" class="margin-toggle">Welbers et al., 2017, p. 252<span class="marginnote">Welbers, K., Van Atteveldt, W., &amp; Benoit, K. (2017). Text analysis in r. <em>Communication Methods and Measures</em>, <em>11</em>(4), 245–265. <a href="https://doi.org/10.1080/19312458.2017.1387238">https://doi.org/10.1080/19312458.2017.1387238</a></span>)</span>. Although this makes it less memory efficient, this lends itself to effective visualisation. The whole logic of these packages is that it works with data which has columns (variables) and rows with single observations. While this is the logic most people know, but it is not always the quickest (and is also not used by <code>quanteda</code>). Yet, it always allows you to look at your data in a way most will understand. First, we run the LDA and have a look at the first 10 terms:</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb234-1"><a href="9-1-latent-dirichlet-allocation.html#cb234-1" aria-hidden="true" tabindex="-1"></a>inaugural_lda10 <span class="ot">&lt;-</span> <span class="fu">LDA</span>(inaugural_dtm, <span class="at">k =</span> <span class="dv">10</span>, <span class="at">method =</span> <span class="st">&quot;Gibbs&quot;</span>,</span>
<span id="cb234-2"><a href="9-1-latent-dirichlet-allocation.html#cb234-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">control =</span> <span class="fu">list</span>(<span class="at">burnin =</span> burnin, <span class="at">iter =</span> iter, <span class="at">thin =</span> thin,</span>
<span id="cb234-3"><a href="9-1-latent-dirichlet-allocation.html#cb234-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">seed =</span> seed, <span class="at">nstart =</span> nstart, <span class="at">best =</span> best))</span>
<span id="cb234-4"><a href="9-1-latent-dirichlet-allocation.html#cb234-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb234-5"><a href="9-1-latent-dirichlet-allocation.html#cb234-5" aria-hidden="true" tabindex="-1"></a><span class="fu">terms</span>(inaugural_lda10, <span class="dv">10</span>)</span></code></pre></div>
<pre><code>##       Topic 1   Topic 2   Topic 3     Topic 4     Topic 5   Topic 6        
##  [1,] &quot;peace&quot;   &quot;us&quot;      &quot;business&quot;  &quot;americans&quot; &quot;every&quot;   &quot;never&quot;        
##  [2,] &quot;world&quot;   &quot;new&quot;     &quot;may&quot;       &quot;citizens&quot;  &quot;great&quot;   &quot;must&quot;         
##  [3,] &quot;nations&quot; &quot;people&quot;  &quot;congress&quot;  &quot;freedom&quot;   &quot;nation&quot;  &quot;republic&quot;     
##  [4,] &quot;free&quot;    &quot;america&quot; &quot;policy&quot;    &quot;country&quot;   &quot;men&quot;     &quot;civilization&quot; 
##  [5,] &quot;freedom&quot; &quot;must&quot;    &quot;states&quot;    &quot;president&quot; &quot;life&quot;    &quot;order&quot;        
##  [6,] &quot;can&quot;     &quot;world&quot;   &quot;executive&quot; &quot;never&quot;     &quot;good&quot;    &quot;war&quot;          
##  [7,] &quot;shall&quot;   &quot;can&quot;     &quot;made&quot;      &quot;common&quot;    &quot;part&quot;    &quot;concern&quot;      
##  [8,] &quot;life&quot;    &quot;nation&quot;  &quot;necessary&quot; &quot;courage&quot;   &quot;upon&quot;    &quot;understanding&quot;
##  [9,] &quot;may&quot;     &quot;one&quot;     &quot;trade&quot;     &quot;day&quot;       &quot;action&quot;  &quot;tasks&quot;        
## [10,] &quot;hope&quot;    &quot;time&quot;    &quot;hope&quot;      &quot;across&quot;    &quot;purpose&quot; &quot;production&quot;   
##       Topic 7      Topic 8       Topic 9      Topic 10   
##  [1,] &quot;change&quot;     &quot;united&quot;      &quot;government&quot; &quot;first&quot;    
##  [2,] &quot;generation&quot; &quot;liberty&quot;     &quot;upon&quot;       &quot;need&quot;     
##  [3,] &quot;journey&quot;    &quot;human&quot;       &quot;can&quot;        &quot;love&quot;     
##  [4,] &quot;hands&quot;      &quot;democracy&quot;   &quot;people&quot;     &quot;days&quot;     
##  [5,] &quot;weapons&quot;    &quot;believe&quot;     &quot;country&quot;    &quot;things&quot;   
##  [6,] &quot;forth&quot;      &quot;states&quot;      &quot;progress&quot;   &quot;back&quot;     
##  [7,] &quot;powerful&quot;   &quot;alone&quot;       &quot;must&quot;       &quot;hand&quot;     
##  [8,] &quot;enduring&quot;   &quot;security&quot;    &quot;law&quot;        &quot;friends&quot;  
##  [9,] &quot;greatness&quot;  &quot;millions&quot;    &quot;system&quot;     &quot;unity&quot;    
## [10,] &quot;words&quot;      &quot;opportunity&quot; &quot;political&quot;  &quot;president&quot;</code></pre>
<p>Here, we can see that the first topic is most concerned with words referring to peace and freedom, the second with references to the people, the third with businesses, as so on. While we can interpret our topics this way, a better way might be to visualise the results. For this, we will use the <code>tidy</code> command to prepare the dataset for visualisation. Then, we tell the command to use the information from the <em>beta</em> column, which contains the probability of a word occurring in a certain topic:</p>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb236-1"><a href="9-1-latent-dirichlet-allocation.html#cb236-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidytext)</span>
<span id="cb236-2"><a href="9-1-latent-dirichlet-allocation.html#cb236-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb236-3"><a href="9-1-latent-dirichlet-allocation.html#cb236-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb236-4"><a href="9-1-latent-dirichlet-allocation.html#cb236-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb236-5"><a href="9-1-latent-dirichlet-allocation.html#cb236-5" aria-hidden="true" tabindex="-1"></a>inaugural_lda10_topics <span class="ot">&lt;-</span> <span class="fu">tidy</span>(inaugural_lda10, <span class="at">matrix =</span> <span class="st">&quot;beta&quot;</span>)</span></code></pre></div>
<p>If we would look into the dataset now, we would see that it has 63130 observations with 3 variables. These are the number of the topic, the word (the term) and the <strong>beta</strong> - the chance that the word occurs in that topic. We now want to visualise only the top ten words for each topic in a bar plot. Also, we want the graphs of each of these ten topics to appear in a single graph. To make this happen, we first have to select the top ten words for each topic. We do so again using a pipe (which is the <code>%&gt;%</code> command). This pipe transports an output of a command to another one before saving it. So here, we take our data set and group it by topic using the <code>group_by</code> command. This command groups the dataset into 10 groups, each for every topic. What this allows us is to calculate things that we otherwise calculate for the whole data-set but here calculate for the groups instead. We then do so and select the top 10 terms (based on their beta value), using <code>top_n</code>. We then ungroup again (to make R view it as a single data-set), and use the <code>arrange</code> function to ensure the data-set sorts the topics in an increasing and the beta values in a decreasing fashion. Finally, we save this into a new object:</p>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="9-1-latent-dirichlet-allocation.html#cb237-1" aria-hidden="true" tabindex="-1"></a>inaugural_lda10_topterms <span class="ot">&lt;-</span> inaugural_lda10_topics <span class="sc">%&gt;%</span></span>
<span id="cb237-2"><a href="9-1-latent-dirichlet-allocation.html#cb237-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(topic) <span class="sc">%&gt;%</span></span>
<span id="cb237-3"><a href="9-1-latent-dirichlet-allocation.html#cb237-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">top_n</span>(<span class="dv">10</span>, beta) <span class="sc">%&gt;%</span></span>
<span id="cb237-4"><a href="9-1-latent-dirichlet-allocation.html#cb237-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb237-5"><a href="9-1-latent-dirichlet-allocation.html#cb237-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">arrange</span>(topic, <span class="sc">-</span>beta)</span></code></pre></div>
<p>If we now look at the data set, we see that it is much smaller and has the topics ordered. Yet, before we can plot this we have to ensure that (seen from top to bottom), all the beta for the first topic come first, then for the second topic, and so on. To do so, we use the <code>mutate</code> command, and redefine the term variable so that it is re-ordered based first on the term and then on the beta value. The result is a data frame with first the first topic, then the second topic etc., and with the beta values ordered within each topic. We then make the figure, with the terms on the horizontal axis and the beta values and the vertical axes, and have the bars this generates coloured by topic. Also, we switch off the legend (which we do not need) and use the <code>facet_wrap</code> command to split up the total graph (which would have 107 bars otherwise - 107 bars and not a 100 because some terms had the same value for beta). We set the options for the scales to be <strong>free</strong> as it might be that the beta values for some topics are larger or smaller than for the others. Finally, we flip the graphs and make the x-axis the y-axis and vice versa, as this makes the picture more clear:</p>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="9-1-latent-dirichlet-allocation.html#cb238-1" aria-hidden="true" tabindex="-1"></a>inaugural_lda10_topterms <span class="sc">%&gt;%</span></span>
<span id="cb238-2"><a href="9-1-latent-dirichlet-allocation.html#cb238-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">term =</span> <span class="fu">reorder</span>(term, beta)) <span class="sc">%&gt;%</span></span>
<span id="cb238-3"><a href="9-1-latent-dirichlet-allocation.html#cb238-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(term, beta, <span class="at">fill =</span> <span class="fu">factor</span>(topic))) <span class="sc">+</span> <span class="fu">geom_col</span>(<span class="at">show.legend =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb238-4"><a href="9-1-latent-dirichlet-allocation.html#cb238-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">facet_wrap</span>(<span class="sc">~</span>topic, <span class="at">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="sc">+</span> <span class="fu">coord_flip</span>()</span></code></pre></div>
<p><img src="Intro-to-Quantitative-Text-Analysis_files/figure-html/unnamed-chunk-157-1.png" width="672"  /></p>
<p>What is clear here is that looking at only the words in each topic only says so much. In the first topic, the term “peace” is more important than anything else, and so is “us” in topic number 2. Also, in topic number ten, we see that both “first” and “need” are of equal importance.</p>
<p>Another question we can ask is how much of each topic is in each of the documents. Put in another way: do certain documents talk more about certain topics than others? To see this, we first generate a new data frame with this information, known as the <em>gamma</em> value for each document:</p>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb239-1"><a href="9-1-latent-dirichlet-allocation.html#cb239-1" aria-hidden="true" tabindex="-1"></a>inaugural_lda10_documents <span class="ot">&lt;-</span> <span class="fu">tidy</span>(inaugural_lda10, <span class="at">matrix =</span> <span class="st">&quot;gamma&quot;</span>)</span></code></pre></div>
<p>We then go through similar steps to make the data set ready for use and prepare the graph. For the graph, the only steps we do different are to force R to label each topic on the axis (as otherwise it will treat it as a continuous variable and come up with useless values such as 7.5), and to give it a different look (using the <code>theme_classic()</code> command):</p>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="9-1-latent-dirichlet-allocation.html#cb240-1" aria-hidden="true" tabindex="-1"></a>inaugural_lda10_toptopics <span class="ot">&lt;-</span> inaugural_lda10_documents <span class="sc">%&gt;%</span></span>
<span id="cb240-2"><a href="9-1-latent-dirichlet-allocation.html#cb240-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(document) <span class="sc">%&gt;%</span></span>
<span id="cb240-3"><a href="9-1-latent-dirichlet-allocation.html#cb240-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">top_n</span>(<span class="dv">10</span>, gamma) <span class="sc">%&gt;%</span></span>
<span id="cb240-4"><a href="9-1-latent-dirichlet-allocation.html#cb240-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb240-5"><a href="9-1-latent-dirichlet-allocation.html#cb240-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">arrange</span>(topic, <span class="sc">-</span>gamma)</span></code></pre></div>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="9-1-latent-dirichlet-allocation.html#cb241-1" aria-hidden="true" tabindex="-1"></a>inaugural_lda10_toptopics <span class="sc">%&gt;%</span></span>
<span id="cb241-2"><a href="9-1-latent-dirichlet-allocation.html#cb241-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">term =</span> <span class="fu">reorder</span>(topic, gamma)) <span class="sc">%&gt;%</span></span>
<span id="cb241-3"><a href="9-1-latent-dirichlet-allocation.html#cb241-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(topic, gamma, <span class="at">fill =</span> <span class="fu">factor</span>(topic))) <span class="sc">+</span> <span class="fu">geom_col</span>(<span class="at">show.legend =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb241-4"><a href="9-1-latent-dirichlet-allocation.html#cb241-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>)) <span class="sc">+</span> <span class="fu">facet_wrap</span>(<span class="sc">~</span>document,</span>
<span id="cb241-5"><a href="9-1-latent-dirichlet-allocation.html#cb241-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="sc">+</span> <span class="fu">coord_flip</span>() <span class="sc">+</span> <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="Intro-to-Quantitative-Text-Analysis_files/figure-html/unnamed-chunk-160-1.png" width="672"  /></p>
<p>Here, we see that in 1929 Hoover talked most often about topic 9 (focusing on government), Biden in 2021 focused on words like “us” and “people,” while in 1945 Roosevelt seemed to favour both the people and topics referring to peace. Again, our exact conclusions of course depend on how we interpret the topics.</p>
</div>
<p style="text-align: center;">
<a href="9-unsupervised-methods.html"><button class="btn btn-default">Previous</button></a>
<a href="9-2-seeded-latent-dirichlet-allocation.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
