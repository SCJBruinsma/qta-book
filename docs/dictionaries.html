<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Dictionaries | Quantitative Text Analysis</title>
  <meta name="description" content="Theory and Methods for Quantitative Text Analysis" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Dictionaries | Quantitative Text Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Theory and Methods for Quantitative Text Analysis" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Dictionaries | Quantitative Text Analysis" />
  
  <meta name="twitter:description" content="Theory and Methods for Quantitative Text Analysis" />
  

<meta name="author" content="Kostas Gemenis &amp; Bastiaan Bruinsma" />


<meta name="date" content="2021-04-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="reliability-and-validity.html"/>
<link rel="next" href="scaling.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Intro to Quantitative Text Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Foreword</a></li>
<li class="chapter" data-level="2" data-path="getting-ready.html"><a href="getting-ready.html"><i class="fa fa-check"></i><b>2</b> Getting Ready</a>
<ul>
<li class="chapter" data-level="2.1" data-path="getting-ready.html"><a href="getting-ready.html#installing-r"><i class="fa fa-check"></i><b>2.1</b> Installing R</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="getting-ready.html"><a href="getting-ready.html#r-on-windows"><i class="fa fa-check"></i><b>2.1.1</b> R on Windows</a></li>
<li class="chapter" data-level="2.1.2" data-path="getting-ready.html"><a href="getting-ready.html#r-on-linux"><i class="fa fa-check"></i><b>2.1.2</b> R on Linux</a></li>
<li class="chapter" data-level="2.1.3" data-path="getting-ready.html"><a href="getting-ready.html#r-on-macos"><i class="fa fa-check"></i><b>2.1.3</b> R on macOS</a></li>
<li class="chapter" data-level="2.1.4" data-path="getting-ready.html"><a href="getting-ready.html#r-in-the-cloud"><i class="fa fa-check"></i><b>2.1.4</b> R in the Cloud</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="getting-ready.html"><a href="getting-ready.html#packages"><i class="fa fa-check"></i><b>2.2</b> Packages</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="getting-ready.html"><a href="getting-ready.html#installing-from-cran"><i class="fa fa-check"></i><b>2.2.1</b> Installing from CRAN</a></li>
<li class="chapter" data-level="2.2.2" data-path="getting-ready.html"><a href="getting-ready.html#installing-from-github"><i class="fa fa-check"></i><b>2.2.2</b> Installing from GitHub</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="getting-ready.html"><a href="getting-ready.html#quanteda"><i class="fa fa-check"></i><b>2.3</b> Quanteda</a></li>
<li class="chapter" data-level="2.4" data-path="getting-ready.html"><a href="getting-ready.html#issues-bugs-and-errors"><i class="fa fa-check"></i><b>2.4</b> Issues, Bugs and Errors</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="preparing-the-data.html"><a href="preparing-the-data.html"><i class="fa fa-check"></i><b>3</b> Preparing the Data</a>
<ul>
<li class="chapter" data-level="3.1" data-path="preparing-the-data.html"><a href="preparing-the-data.html#text-in-r"><i class="fa fa-check"></i><b>3.1</b> Text in R</a></li>
<li class="chapter" data-level="3.2" data-path="preparing-the-data.html"><a href="preparing-the-data.html#import-.pdf-files"><i class="fa fa-check"></i><b>3.2</b> Import .pdf Files</a></li>
<li class="chapter" data-level="3.3" data-path="preparing-the-data.html"><a href="preparing-the-data.html#import-.txt-files"><i class="fa fa-check"></i><b>3.3</b> Import .txt Files</a></li>
<li class="chapter" data-level="3.4" data-path="preparing-the-data.html"><a href="preparing-the-data.html#import-.csv-files"><i class="fa fa-check"></i><b>3.4</b> Import .csv Files</a></li>
<li class="chapter" data-level="3.5" data-path="preparing-the-data.html"><a href="preparing-the-data.html#import-using-web-scraping"><i class="fa fa-check"></i><b>3.5</b> Import using Web Scraping</a></li>
<li class="chapter" data-level="3.6" data-path="preparing-the-data.html"><a href="preparing-the-data.html#import-from-an-api"><i class="fa fa-check"></i><b>3.6</b> Import from an API</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html"><i class="fa fa-check"></i><b>4</b> Reliability and validity</a>
<ul>
<li class="chapter" data-level="4.1" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#measuring-inter-coder-agreement"><i class="fa fa-check"></i><b>4.1</b> Measuring inter-coder agreement</a></li>
<li class="chapter" data-level="4.2" data-path="reliability-and-validity.html"><a href="reliability-and-validity.html#visualizing-the-quality-of-coding"><i class="fa fa-check"></i><b>4.2</b> Visualizing the quality of coding</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="dictionaries.html"><a href="dictionaries.html"><i class="fa fa-check"></i><b>5</b> Dictionaries</a>
<ul>
<li class="chapter" data-level="5.1" data-path="dictionaries.html"><a href="dictionaries.html#working-with-a-corpus"><i class="fa fa-check"></i><b>5.1</b> Working with a Corpus</a></li>
<li class="chapter" data-level="5.2" data-path="dictionaries.html"><a href="dictionaries.html#standard-dictionary-analysis"><i class="fa fa-check"></i><b>5.2</b> Standard Dictionary Analysis</a></li>
<li class="chapter" data-level="5.3" data-path="dictionaries.html"><a href="dictionaries.html#sentiment-analysis"><i class="fa fa-check"></i><b>5.3</b> Sentiment Analysis</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="scaling.html"><a href="scaling.html"><i class="fa fa-check"></i><b>6</b> Scaling</a>
<ul>
<li class="chapter" data-level="6.1" data-path="scaling.html"><a href="scaling.html#wordscores"><i class="fa fa-check"></i><b>6.1</b> Wordscores</a></li>
<li class="chapter" data-level="6.2" data-path="scaling.html"><a href="scaling.html#wordfish"><i class="fa fa-check"></i><b>6.2</b> Wordfish</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="supervised-methods.html"><a href="supervised-methods.html"><i class="fa fa-check"></i><b>7</b> Supervised Methods</a>
<ul>
<li class="chapter" data-level="7.1" data-path="supervised-methods.html"><a href="supervised-methods.html#support-vector-machines"><i class="fa fa-check"></i><b>7.1</b> Support Vector Machines</a></li>
<li class="chapter" data-level="7.2" data-path="supervised-methods.html"><a href="supervised-methods.html#naive-bayes"><i class="fa fa-check"></i><b>7.2</b> Naive Bayes</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="unsupervised-methods.html"><a href="unsupervised-methods.html"><i class="fa fa-check"></i><b>8</b> Unsupervised Methods</a>
<ul>
<li class="chapter" data-level="8.1" data-path="unsupervised-methods.html"><a href="unsupervised-methods.html#latent-dirichlet-allocation"><i class="fa fa-check"></i><b>8.1</b> Latent Dirichlet Allocation</a></li>
<li class="chapter" data-level="8.2" data-path="unsupervised-methods.html"><a href="unsupervised-methods.html#correspondence-analysis"><i class="fa fa-check"></i><b>8.2</b> Correspondence Analysis</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="bruinsma@soz.uni-frankfurt.de" target="blank">Bastiaan Bruinsma</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Quantitative Text Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="dictionaries" class="section level1" number="5">
<h1><span class="header-section-number">Chapter 5</span> Dictionaries</h1>
<p>One of the simplest forms of quantitative text analysis is dictionary analysis. We can define dictionary methods as those which simply use the rate at which key words appear in a text to classify documents into categories or to measure the extent to which documents belong to particular categories, without making further assumptions. In many respects, dictionary methods present a non-statistical, categorical analysis approach.</p>
<p>One of the most well-known examples of using dictionary methods is the measuring the tone in newspaper articles, speeches, children’s writings, and so on, by using the so-called sentiment analysis dictionaries. Another well-known example is the measuring of policy content in different documents as illustrated by the Policy Agendas Project dictionary (<span class="citation"><a href="references.html#ref-Albaugh2013" role="doc-biblioref">Albaugh et al.</a> (<a href="references.html#ref-Albaugh2013" role="doc-biblioref">2013</a>)</span>).</p>
<p>Here, we will carry out two such analyses, the first a standard analysis and the second focusing on sentiment. For the former, we will use political party manifestos, while for the latter we will use movie reviews. First, though, we will have a look at the data itself and which tools <code>quanteda</code> has to investigate it.</p>
<div id="working-with-a-corpus" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Working with a Corpus</h2>
<p>In the previous chapter, we saw that there are many ways to load our data into R. Most often, the result of this is is a data frame which contains the texts. Besides, it also often has information on the name of the documents, the number of sentences and so on.</p>
<p>Within <code>quanteda</code>, the main way to store documents is in the form of a <code>corpus</code> object. This object contains all the information that comes with the texts and does not change during our analysis. Instead, we make copies of the main corpus, change them into the type we need, and run our analyses on them. The advantage of this is that we always can go back to our original data.</p>
<p>Apart from importing texts ourselves, <code>quanteda</code> contains several corpora as well. Here, we use one of these, which contains the electoral manifestos of political parties in the United Kingdom. For this, we first have to load the main package and the package that contains the corpus, and then load the data into R:</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="dictionaries.html#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(quanteda)</span>
<span id="cb64-2"><a href="dictionaries.html#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(quanteda.corpora)</span>
<span id="cb64-3"><a href="dictionaries.html#cb64-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-4"><a href="dictionaries.html#cb64-4" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(data_corpus_ukmanifestos)</span>
<span id="cb64-5"><a href="dictionaries.html#cb64-5" aria-hidden="true" tabindex="-1"></a>data_corpus_ukmanifestos</span></code></pre></div>
<pre><code>## Corpus consisting of 101 documents and 6 docvars.
## UK_natl_1945_en_Con :
## &quot;CONSERVATIVE PARTY: 1945  Mr. Churchill&#39;s Declaration of Pol...&quot;
## 
## UK_natl_1945_en_Lab :
## &quot;Labour Party: 1945  Let Us Face the Future: A Declaration of...&quot;
## 
## UK_natl_1945_en_Lib :
## &quot;LIBERAL MANIFESTO 1945  20 Point Manifesto of the Liberal Pa...&quot;
## 
## UK_natl_1950_en_Con :
## &quot;CONSERVATIVE PARTY: 1950  This is the Road: The Conservative...&quot;
## 
## UK_natl_1950_en_Lab :
## &quot;LABOUR PARTY: 1950  Let Us Win Through Together: A Declarati...&quot;
## 
## UK_natl_1950_en_Lib :
## &quot;LIBERAL PARTY 1950  No Easy Way: Britain&#39;s Problems and the ...&quot;
## 
## [ reached max_ndoc ... 95 more documents ]</code></pre>
<p>You should now see the corpus appear in the Environment tab. If you click on it, you can see, amongst others, that the corpus comes with information on the Year of the release of the manifesto and the party it belongs to. As the corpus is quite large, we make it a bit more manageable by only selecting the manifestos for the years 2001 and 2005 for the main five parties. We can do this by using the <code>corpus_subset</code> command for both:</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="dictionaries.html#cb66-1" aria-hidden="true" tabindex="-1"></a>corpus_manifestos <span class="ot">&lt;-</span> <span class="fu">corpus_subset</span>(data_corpus_ukmanifestos, Year <span class="sc">==</span> <span class="dv">2001</span> <span class="sc">|</span> Year <span class="sc">==</span> <span class="dv">2005</span>)</span>
<span id="cb66-2"><a href="dictionaries.html#cb66-2" aria-hidden="true" tabindex="-1"></a>corpus_manifestos <span class="ot">&lt;-</span> <span class="fu">corpus_subset</span>(corpus_manifestos, Party<span class="sc">==</span><span class="st">&quot;Lab&quot;</span> <span class="sc">|</span> Party<span class="sc">==</span><span class="st">&quot;LD&quot;</span> <span class="sc">|</span> Party <span class="sc">==</span> <span class="st">&quot;Con&quot;</span> <span class="sc">|</span> Party<span class="sc">==</span> <span class="st">&quot;SNP&quot;</span> <span class="sc">|</span> Party<span class="sc">==</span> <span class="st">&quot;PCy&quot;</span>)</span></code></pre></div>
<p>Now we have our corpus, we can start with the analysis. As noted, we try not to carry out any analysis on the corpus itself. Instead, we keep it as it is and work on its copies. Often, this means transforming the data into another shape. One of the more popular shapes is the data frequency matrix (dfm). This is a matrix which contains the documents in the rows and the word counts for each word in the columns.</p>
<p>Before we can do so however, we have to split up our texts into unique words. To do this, we first have to construct a <code>tokens</code> object. In the command that we use to do this, we can specify how we want our texts to be split (here we use the standard option), and in addition clean our data a bit. For example, we can specify that we want to convert all the texts into lowercase and remove any numbers and special characters.</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="dictionaries.html#cb67-1" aria-hidden="true" tabindex="-1"></a>data_manifestos_tokens <span class="ot">&lt;-</span> <span class="fu">tokens</span>(corpus_manifestos, <span class="at">what =</span> <span class="st">&quot;word&quot;</span>, </span>
<span id="cb67-2"><a href="dictionaries.html#cb67-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">remove_punct =</span> <span class="cn">TRUE</span>, <span class="at">remove_symbols =</span> <span class="cn">TRUE</span>, <span class="at">remove_numbers =</span> <span class="cn">TRUE</span>, </span>
<span id="cb67-3"><a href="dictionaries.html#cb67-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">remove_url =</span> <span class="cn">TRUE</span>, <span class="at">remove_separators =</span> <span class="cn">TRUE</span>, <span class="at">split_hyphens =</span> <span class="cn">FALSE</span>, </span>
<span id="cb67-4"><a href="dictionaries.html#cb67-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">include_docvars =</span> <span class="cn">TRUE</span>, <span class="at">padding =</span> <span class="cn">FALSE</span>, <span class="at">verbose =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## Creating a tokens object from a corpus input...</code></pre>
<pre><code>##  ...starting tokenization</code></pre>
<pre><code>##  ...UK_natl_2001_en_Con to UK_natl_2005_en_SNP</code></pre>
<pre><code>##  ...preserving hyphens</code></pre>
<pre><code>##  ...preserving social media tags (#, @)</code></pre>
<pre><code>##  ...segmenting into words</code></pre>
<pre><code>##  ...10,488 unique types</code></pre>
<pre><code>##  ...removing separators, punctuation, symbols, numbers, URLs</code></pre>
<pre><code>##  ...complete, elapsed time: 0.673 seconds.</code></pre>
<pre><code>## Finished constructing tokens from 10 documents.</code></pre>
<p>We can also remove certain stopwords so that words like “and” or “the” do not influence our analysis too much. We can either specify these words ourselves or we can use a list that is already present in R. To see this list, type <code>stopwords("english")</code> in the console. Stopwords for other languages are also available (such as German, French and Spanish). Even more stopwords can be found in the <code>stopword</code> package, that can easily be integrated with <code>quanteda</code>. For now, we will use the English ones. First, however, as all the stopwords are lower-case, we will have to lower case our words as well:</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="dictionaries.html#cb78-1" aria-hidden="true" tabindex="-1"></a>data_manifestos_tokens <span class="ot">&lt;-</span> <span class="fu">tokens_tolower</span>(data_manifestos_tokens, <span class="at">keep_acronyms =</span> <span class="cn">FALSE</span>)</span>
<span id="cb78-2"><a href="dictionaries.html#cb78-2" aria-hidden="true" tabindex="-1"></a>data_manifestos_tokens <span class="ot">&lt;-</span> <span class="fu">tokens_select</span>(data_manifestos_tokens, <span class="fu">stopwords</span>(<span class="st">&quot;english&quot;</span>), <span class="at">selection =</span> <span class="st">&quot;remove&quot;</span>)</span></code></pre></div>
<p>Then, we can construct our dfm:</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="dictionaries.html#cb79-1" aria-hidden="true" tabindex="-1"></a>data_manifestos_dfm <span class="ot">&lt;-</span> <span class="fu">dfm</span>(data_manifestos_tokens)</span></code></pre></div>
<p>One thing we can do with this dfm is to generate a frequency graph using the <code>topfeatures</code> function. For this, we first have to save the 50 most frequently occurring words in our texts:</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="dictionaries.html#cb80-1" aria-hidden="true" tabindex="-1"></a>features <span class="ot">&lt;-</span> <span class="fu">topfeatures</span>(data_manifestos_dfm, <span class="dv">50</span>)</span></code></pre></div>
<p>We then have to transform this object into a data frame, and sort it by decreasing frequency:</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="dictionaries.html#cb81-1" aria-hidden="true" tabindex="-1"></a>features_plot <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">list</span>(<span class="at">term =</span> <span class="fu">names</span>(features),<span class="at">frequency =</span> <span class="fu">unname</span>(features)))</span>
<span id="cb81-2"><a href="dictionaries.html#cb81-2" aria-hidden="true" tabindex="-1"></a>features_plot<span class="sc">$</span>term <span class="ot">&lt;-</span> <span class="fu">with</span>(features_plot, <span class="fu">reorder</span>(term, <span class="sc">-</span>frequency))</span></code></pre></div>
<p>Then we can plot the results:</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="dictionaries.html#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb82-2"><a href="dictionaries.html#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(features_plot) <span class="sc">+</span> </span>
<span id="cb82-3"><a href="dictionaries.html#cb82-3" aria-hidden="true" tabindex="-1"></a> <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x=</span>term, <span class="at">y=</span>frequency)) <span class="sc">+</span></span>
<span id="cb82-4"><a href="dictionaries.html#cb82-4" aria-hidden="true" tabindex="-1"></a> <span class="fu">theme_classic</span>()<span class="sc">+</span></span>
<span id="cb82-5"><a href="dictionaries.html#cb82-5" aria-hidden="true" tabindex="-1"></a> <span class="fu">theme</span>(<span class="at">axis.text.x=</span><span class="fu">element_text</span>(<span class="at">angle=</span><span class="dv">90</span>, <span class="at">hjust=</span><span class="dv">1</span>))</span></code></pre></div>
<p><img src="Quantitative-Text-Analysis_files/figure-html/unnamed-chunk-56-1.png" width="672" /></p>
<p>We can also generate word clouds. As these show all the words we have, we will trim our dfm first to remove all those words that occurred less than 40 times. We can do this with the <code>dfm_trim</code> function. Then, we can use this newly trimmed dfm to generate the word cloud:</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="dictionaries.html#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(quanteda.textplots)</span>
<span id="cb83-2"><a href="dictionaries.html#cb83-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-3"><a href="dictionaries.html#cb83-3" aria-hidden="true" tabindex="-1"></a>wordcloud_dfm_trim <span class="ot">&lt;-</span> <span class="fu">dfm_trim</span>(data_manifestos_dfm, <span class="at">min_termfreq =</span> <span class="dv">40</span>)</span>
<span id="cb83-4"><a href="dictionaries.html#cb83-4" aria-hidden="true" tabindex="-1"></a><span class="fu">textplot_wordcloud</span>(wordcloud_dfm_trim)</span></code></pre></div>
<p><img src="Quantitative-Text-Analysis_files/figure-html/unnamed-chunk-57-1.png" width="672" /></p>
<p>If we would want to, we can also split up this word cloud based on which words belong to which parties. For this, we have to generate a new dfm and within it, specify the groups that well which words belong to which party:</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="dictionaries.html#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(quanteda.textplots)</span>
<span id="cb84-2"><a href="dictionaries.html#cb84-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-3"><a href="dictionaries.html#cb84-3" aria-hidden="true" tabindex="-1"></a>wordcloud_dfm_comp <span class="ot">&lt;-</span> <span class="fu">dfm_group</span>(data_manifestos_dfm, <span class="at">groups =</span> Party)</span>
<span id="cb84-4"><a href="dictionaries.html#cb84-4" aria-hidden="true" tabindex="-1"></a>wordcloud_dfm_comp <span class="ot">&lt;-</span> <span class="fu">dfm_trim</span>(wordcloud_dfm_comp, <span class="at">min_termfreq =</span> <span class="dv">20</span>, </span>
<span id="cb84-5"><a href="dictionaries.html#cb84-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">max_words =</span> <span class="dv">40</span>)</span>
<span id="cb84-6"><a href="dictionaries.html#cb84-6" aria-hidden="true" tabindex="-1"></a><span class="fu">textplot_wordcloud</span>(wordcloud_dfm_comp, <span class="at">comparison =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="Quantitative-Text-Analysis_files/figure-html/unnamed-chunk-58-1.png" width="672" /></p>
</div>
<div id="standard-dictionary-analysis" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Standard Dictionary Analysis</h2>
<p>Now we have the first idea of our data, we can turn to a dictionary analysis. We can do so either by making a dictionary ourselves or using an off-the-shelf version. For the latter, we can either import the files we already have into R or use some of the versions that come with the <code>quanteda.dictionaries</code> package. For this, we first load the package:</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="dictionaries.html#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(quanteda.dictionaries)</span></code></pre></div>
<p>We then apply one of these dictionaries to the document feature matrix we made earlier. As a dictionary, we will use the one made by <span class="citation"><a href="references.html#ref-Laver2000a" role="doc-biblioref">Laver and Garry</a> (<a href="references.html#ref-Laver2000a" role="doc-biblioref">2000</a>)</span>, meant for estimating policy positions from political texts. We first load this dictionary into R and then run it on the dfm using the <code>dfm_lookup</code> command:</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="dictionaries.html#cb86-1" aria-hidden="true" tabindex="-1"></a>data_dictionary_LaverGarry</span>
<span id="cb86-2"><a href="dictionaries.html#cb86-2" aria-hidden="true" tabindex="-1"></a>dictionary_results <span class="ot">&lt;-</span> <span class="fu">dfm_lookup</span>(data_manifestos_dfm, data_dictionary_LaverGarry)</span>
<span id="cb86-3"><a href="dictionaries.html#cb86-3" aria-hidden="true" tabindex="-1"></a>dictionary_results</span></code></pre></div>
<p>Apart from off-the-shelf dictionaries, it is also possible to create our own which could suit our research question better. One approach in dictionary construction is to use prior theory deductively to come up with different categories and their associated words. Another approach is to use reference texts in order to come up with categories and words inductively. We can also combine different dictionaries as illustrated by <span class="citation"><a href="references.html#ref-Young2012" role="doc-biblioref">Young and Soroka</a> (<a href="references.html#ref-Young2012" role="doc-biblioref">2012</a>)</span>, or different dictionaries and keywords from categories in manual coding scheme (<span class="citation"><a href="references.html#ref-Lind2019" role="doc-biblioref">Lind et al.</a> (<a href="references.html#ref-Lind2019" role="doc-biblioref">2019</a>)</span>). Finally, one can use expert or crowdcoding assessments to determine the words that best match different categories in a dictionary (<span class="citation"><a href="references.html#ref-Haselmayer2017" role="doc-biblioref">Haselmayer and Jenny</a> (<a href="references.html#ref-Haselmayer2017" role="doc-biblioref">2017</a>)</span>).</p>
<p>If we want to create our own dictionary in <code>quanteda</code> we use the same commands as above, but we first have to create the dictionary. To do so, we specify the words in a named list. This list contains keys (the words we want to look for) and the categories to which they belong. We then transform this list into a dictionary. Here, we choose some words which we believe will allow us to easily identify the different parties:</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="dictionaries.html#cb87-1" aria-hidden="true" tabindex="-1"></a>dic_list <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">economy =</span> <span class="fu">c</span>(<span class="st">&quot;tax*&quot;</span>, <span class="st">&quot;vat&quot;</span>, <span class="st">&quot;trade&quot;</span>), <span class="at">social =</span> <span class="fu">c</span>(<span class="st">&quot;NHS&quot;</span>, </span>
<span id="cb87-2"><a href="dictionaries.html#cb87-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;GP&quot;</span>, <span class="st">&quot;health&quot;</span>), <span class="at">devolution =</span> <span class="fu">c</span>(<span class="st">&quot;referendum&quot;</span>, <span class="st">&quot;leave&quot;</span>, <span class="st">&quot;independence&quot;</span>), </span>
<span id="cb87-3"><a href="dictionaries.html#cb87-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">europe =</span> <span class="fu">c</span>(<span class="st">&quot;Brussels&quot;</span>, <span class="st">&quot;remain&quot;</span>, <span class="st">&quot;EU&quot;</span>))</span>
<span id="cb87-4"><a href="dictionaries.html#cb87-4" aria-hidden="true" tabindex="-1"></a>dic_created <span class="ot">&lt;-</span> <span class="fu">dictionary</span>(dic_list, <span class="at">tolower =</span> <span class="cn">FALSE</span>)</span>
<span id="cb87-5"><a href="dictionaries.html#cb87-5" aria-hidden="true" tabindex="-1"></a>dic_created</span></code></pre></div>
<pre><code>## Dictionary object with 4 key entries.
## - [economy]:
##   - tax*, vat, trade
## - [social]:
##   - NHS, GP, health
## - [devolution]:
##   - referendum, leave, independence
## - [europe]:
##   - Brussels, remain, EU</code></pre>
<p>If you compare the <code>dic_list</code> file with the <code>data_dictionary_LaverGarry</code> file, you will find that it has the same structure. To see the result, we can use the same command:</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="dictionaries.html#cb89-1" aria-hidden="true" tabindex="-1"></a>dictionary_created <span class="ot">&lt;-</span> <span class="fu">dfm_lookup</span>(data_manifestos_dfm, dic_created)</span>
<span id="cb89-2"><a href="dictionaries.html#cb89-2" aria-hidden="true" tabindex="-1"></a>dictionary_created</span></code></pre></div>
<pre><code>## Document-feature matrix of: 10 documents, 4 features (2.50% sparse) and 6 docvars.
##                      features
## docs                  economy social devolution europe
##   UK_natl_2001_en_Con     108     27         13     14
##   UK_natl_2001_en_Lab      89     86         20     36
##   UK_natl_2001_en_LD      104     74         12     37
##   UK_natl_2001_en_PCy      14     26          1      1
##   UK_natl_2001_en_SNP      51     26         30     10
##   UK_natl_2005_en_Con      37     21          8     10
## [ reached max_ndoc ... 4 more documents ]</code></pre>
<p>Here, we see that the Conservatives are the most active on the Economy together with the Liberal Democrats. Social issues are for Labour, while the SNP is most active on devolution, as are the Liberal Democrats on Europe.</p>
</div>
<div id="sentiment-analysis" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Sentiment Analysis</h2>
<p>The logic of dictionaries is that we can use them to see which kind of topics are present in our documents. Yet, we can also use them to provide us with measurements that are most often related to scaling. One way to do so is with <em>sentiment</em> analysis. Here, we look at whether a certain piece of text is happy, angry, positive, negative, and so on. One case in which this can help us is with movie reviews. These reviews give us a description of a movie and then tell us their opinion. Here, we will use these reviews and apply a sentiment dictionary on them.</p>
<p>First, we load some reviews into R. The corpus we use here contains 50,000 movie reviews, each with a 1-10 rating (amongst others). As 50,000 reviews make the analysis quite slow, we will first select 30 reviews at random from this corpus. We do so via <code>corpus_sample</code>, after which we transform it via a tokens object into a dfm:</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="dictionaries.html#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(quanteda.classifiers)</span>
<span id="cb91-2"><a href="dictionaries.html#cb91-2" aria-hidden="true" tabindex="-1"></a>reviews <span class="ot">&lt;-</span> <span class="fu">corpus_sample</span>(data_corpus_LMRD, <span class="dv">30</span>)</span>
<span id="cb91-3"><a href="dictionaries.html#cb91-3" aria-hidden="true" tabindex="-1"></a>reviews_tokens <span class="ot">&lt;-</span> <span class="fu">tokens</span>(reviews)</span>
<span id="cb91-4"><a href="dictionaries.html#cb91-4" aria-hidden="true" tabindex="-1"></a>reviews_dfm <span class="ot">&lt;-</span> <span class="fu">dfm</span>(reviews_tokens)</span></code></pre></div>
<p>The next step is to load in a sentiment analysis dictionary. Here, we will use the Lexicoder Sentiment Dictionary, included in <code>quanteda</code> and run it on the dfm:</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="dictionaries.html#cb92-1" aria-hidden="true" tabindex="-1"></a>data_dictionary_LSD2015</span>
<span id="cb92-2"><a href="dictionaries.html#cb92-2" aria-hidden="true" tabindex="-1"></a>results_dfm <span class="ot">&lt;-</span> <span class="fu">dfm_lookup</span>(reviews_dfm, data_dictionary_LSD2015)</span>
<span id="cb92-3"><a href="dictionaries.html#cb92-3" aria-hidden="true" tabindex="-1"></a>results_dfm</span></code></pre></div>
<p>The next step is to convert the results to a data frame and view them:</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="dictionaries.html#cb93-1" aria-hidden="true" tabindex="-1"></a>sentiment <span class="ot">&lt;-</span> <span class="fu">convert</span>(results_dfm, <span class="at">to=</span><span class="st">&quot;data.frame&quot;</span>)</span>
<span id="cb93-2"><a href="dictionaries.html#cb93-2" aria-hidden="true" tabindex="-1"></a>sentiment</span></code></pre></div>
<pre><code>##                   doc_id negative positive neg_positive neg_negative
## 1   test/pos/3198_10.txt        2       14            0            0
## 2    test/pos/4234_9.txt       13       15            0            0
## 3     test/pos/591_8.txt        1        6            0            0
## 4  train/neg/10586_1.txt        9        7            0            0
## 5    test/neg/5934_3.txt        8        4            0            0
## 6   test/neg/11664_4.txt       13        6            0            0
## 7   test/neg/12209_3.txt       12       11            0            0
## 8  train/pos/11017_9.txt       13       23            0            0
## 9    test/pos/7711_8.txt        0        8            0            0
## 10   test/pos/4135_8.txt        7        9            0            0
## 11 train/neg/12260_2.txt        7        8            0            0
## 12  train/pos/6768_8.txt        3        5            0            0
## 13  train/neg/2030_4.txt        6       20            0            0
## 14 test/pos/11981_10.txt        2        8            0            0
## 15  train/pos/6543_9.txt        0        4            0            0
## 16   test/neg/7974_1.txt       16        6            0            0
## 17  train/neg/6160_1.txt        6        1            0            0
## 18  train/pos/4501_7.txt        8       19            0            0
## 19  train/pos/3134_8.txt        0        6            0            0
## 20  train/neg/6123_4.txt        3        9            0            0
## 21   train/pos/722_7.txt       13       25            0            0
## 22  test/pos/7026_10.txt        7       11            0            0
## 23   test/pos/3893_8.txt        3        9            0            0
## 24  test/pos/10658_9.txt       28       31            0            0
## 25  train/pos/6866_7.txt        9       11            0            0
## 26   test/pos/2431_9.txt        5        8            0            0
## 27   test/neg/5304_1.txt        4        7            0            0
## 28 train/pos/10881_7.txt       16       12            0            0
## 29  train/neg/9523_3.txt        5        8            0            0
## 30  train/neg/3575_1.txt        5        0            0            0</code></pre>
<p>Since movie reviews usually come with some sort of rating (often in the form of stars), we can see if this relates to the sentiment of the review. To do so, we have to take the rating out of the dfm and place it in a new data-frame with the positive and negative sentiments:</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="dictionaries.html#cb95-1" aria-hidden="true" tabindex="-1"></a>star_data <span class="ot">&lt;-</span> reviews_dfm<span class="sc">@</span>docvars<span class="sc">$</span>rating</span>
<span id="cb95-2"><a href="dictionaries.html#cb95-2" aria-hidden="true" tabindex="-1"></a>stargraph <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">cbind</span>(star_data, sentiment<span class="sc">$</span>negative, sentiment<span class="sc">$</span>positive))</span>
<span id="cb95-3"><a href="dictionaries.html#cb95-3" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(stargraph) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;stars&quot;</span>,<span class="st">&quot;negative&quot;</span>,<span class="st">&quot;positive&quot;</span>)</span></code></pre></div>
<p>To compare the sentiment with the stars, we first have to combine the senitments into a scale. Of the many ways to do so, the simplest is to take the difference between the positive and negative words (positive – negative). Another option is to take the ratio of positive words against both positive and negative (positive/positive+negative). Here, we do both:</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="dictionaries.html#cb96-1" aria-hidden="true" tabindex="-1"></a>sentiment_difference <span class="ot">&lt;-</span> stargraph<span class="sc">$</span>positive <span class="sc">-</span> stargraph<span class="sc">$</span>negative</span>
<span id="cb96-2"><a href="dictionaries.html#cb96-2" aria-hidden="true" tabindex="-1"></a>sentiment_ratio <span class="ot">&lt;-</span> (stargraph<span class="sc">$</span>positive<span class="sc">/</span>(stargraph<span class="sc">$</span>positive <span class="sc">+</span> </span>
<span id="cb96-3"><a href="dictionaries.html#cb96-3" aria-hidden="true" tabindex="-1"></a>    stargraph<span class="sc">$</span>negative))</span>
<span id="cb96-4"><a href="dictionaries.html#cb96-4" aria-hidden="true" tabindex="-1"></a>stargraph <span class="ot">&lt;-</span> <span class="fu">cbind</span>(stargraph, sentiment_difference, sentiment_ratio)</span></code></pre></div>
<p>Then, we can plot the ratings and the scaled sentiment measures together with a linear regression line:</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="dictionaries.html#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb97-2"><a href="dictionaries.html#cb97-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-3"><a href="dictionaries.html#cb97-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(stargraph, <span class="fu">aes</span>(<span class="at">x =</span> sentiment_difference, <span class="at">y =</span> stars)) <span class="sc">+</span> </span>
<span id="cb97-4"><a href="dictionaries.html#cb97-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">shape =</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">method =</span> lm, <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span> </span>
<span id="cb97-5"><a href="dictionaries.html#cb97-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">xlab</span>(<span class="st">&quot;Positive minus Negative&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Stars&quot;</span>) <span class="sc">+</span> <span class="fu">theme_classic</span>()</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="Quantitative-Text-Analysis_files/figure-html/unnamed-chunk-68-1.png" width="672" /></p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="dictionaries.html#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(stargraph, <span class="fu">aes</span>(<span class="at">x =</span> sentiment_ratio, <span class="at">y =</span> stars)) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">shape =</span> <span class="dv">1</span>) <span class="sc">+</span> </span>
<span id="cb99-2"><a href="dictionaries.html#cb99-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_smooth</span>(<span class="at">method =</span> lm, <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Ratio of Positive to Total&quot;</span>) <span class="sc">+</span> </span>
<span id="cb99-3"><a href="dictionaries.html#cb99-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ylab</span>(<span class="st">&quot;Stars&quot;</span>) <span class="sc">+</span> <span class="fu">theme_classic</span>()</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="Quantitative-Text-Analysis_files/figure-html/unnamed-chunk-69-1.png" width="672" /></p>
<p>Finally, we would like to illustrate how one can make inferences by using the output of a dictionary analysis, by estimating confidence intervals around the point estimates. To do so, again the first step is to add a column which will be the total of positive and negative words scored by the dictionary. We do so by copying the data frame to a new data frame and adding a new column filled with NA values:</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="dictionaries.html#cb101-1" aria-hidden="true" tabindex="-1"></a>reviews_bootstrap   <span class="ot">&lt;-</span> sentiment</span>
<span id="cb101-2"><a href="dictionaries.html#cb101-2" aria-hidden="true" tabindex="-1"></a>reviews_bootstrap<span class="sc">$</span>n <span class="ot">&lt;-</span> <span class="cn">NA</span></span></code></pre></div>
<p>We then again specify the number of reviews, the replications that we want and change the data frame into an array:</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="dictionaries.html#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(combinat)</span>
<span id="cb102-2"><a href="dictionaries.html#cb102-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-3"><a href="dictionaries.html#cb102-3" aria-hidden="true" tabindex="-1"></a>nman <span class="ot">&lt;-</span> <span class="fu">nrow</span>(reviews_bootstrap)</span>
<span id="cb102-4"><a href="dictionaries.html#cb102-4" aria-hidden="true" tabindex="-1"></a>nrepl <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb102-5"><a href="dictionaries.html#cb102-5" aria-hidden="true" tabindex="-1"></a>manifBSn <span class="ot">&lt;-</span> manifBSnRand <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="fu">as.matrix</span>(reviews_bootstrap[, </span>
<span id="cb102-6"><a href="dictionaries.html#cb102-6" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>]), <span class="fu">c</span>(nman, <span class="dv">2</span>, nrepl <span class="sc">+</span> <span class="dv">1</span>), <span class="at">dimnames =</span> <span class="fu">list</span>(<span class="dv">1</span><span class="sc">:</span>nman, <span class="fu">names</span>(reviews_bootstrap[, </span>
<span id="cb102-7"><a href="dictionaries.html#cb102-7" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>]), <span class="dv">0</span><span class="sc">:</span>nrepl))</span></code></pre></div>
<p>Then, we bootstrap the word counts for each movie review and compute percentages for each category using a multinomial draw:</p>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="dictionaries.html#cb103-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">apply</span>(manifBSn[<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(manifBSn), , <span class="dv">1</span>], <span class="dv">1</span>, sum)</span>
<span id="cb103-2"><a href="dictionaries.html#cb103-2" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> manifBSn[, , <span class="dv">1</span>]<span class="sc">/</span>n</span>
<span id="cb103-3"><a href="dictionaries.html#cb103-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-4"><a href="dictionaries.html#cb103-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nrepl) {</span>
<span id="cb103-5"><a href="dictionaries.html#cb103-5" aria-hidden="true" tabindex="-1"></a>    manifBSn[, , i] <span class="ot">&lt;-</span> <span class="fu">rmultinomial</span>(n, p)</span>
<span id="cb103-6"><a href="dictionaries.html#cb103-6" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>We can then ask R to compute the quantities of interest. These are standard errors for each category, as well as the percentage coded for each category.</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="dictionaries.html#cb104-1" aria-hidden="true" tabindex="-1"></a>NegativeSE <span class="ot">&lt;-</span> <span class="fu">apply</span>(manifBSn[, <span class="st">&quot;negative&quot;</span>, ]<span class="sc">/</span>n <span class="sc">*</span> <span class="dv">100</span>, <span class="dv">1</span>, sd)</span>
<span id="cb104-2"><a href="dictionaries.html#cb104-2" aria-hidden="true" tabindex="-1"></a>PositiveSE <span class="ot">&lt;-</span> <span class="fu">apply</span>(manifBSn[, <span class="st">&quot;positive&quot;</span>, ]<span class="sc">/</span>n <span class="sc">*</span> <span class="dv">100</span>, <span class="dv">1</span>, sd)</span>
<span id="cb104-3"><a href="dictionaries.html#cb104-3" aria-hidden="true" tabindex="-1"></a>perNegative <span class="ot">&lt;-</span> <span class="fu">apply</span>(manifBSn[, <span class="st">&quot;negative&quot;</span>, ]<span class="sc">/</span>n <span class="sc">*</span> <span class="dv">100</span>, <span class="dv">1</span>, mean)</span>
<span id="cb104-4"><a href="dictionaries.html#cb104-4" aria-hidden="true" tabindex="-1"></a>perPositive <span class="ot">&lt;-</span> <span class="fu">apply</span>(manifBSn[, <span class="st">&quot;positive&quot;</span>, ]<span class="sc">/</span>n <span class="sc">*</span> <span class="dv">100</span>, <span class="dv">1</span>, mean)</span></code></pre></div>
<p>We then save these quantities of interest in a new data frame:</p>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="dictionaries.html#cb105-1" aria-hidden="true" tabindex="-1"></a>dataBS <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">cbind</span>(reviews_bootstrap[, <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>], NegativeSE, </span>
<span id="cb105-2"><a href="dictionaries.html#cb105-2" aria-hidden="true" tabindex="-1"></a>    PositiveSE, perNegative, perPositive))</span></code></pre></div>
<p>Then, we first calculate the confidence intervals and add these:</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="dictionaries.html#cb106-1" aria-hidden="true" tabindex="-1"></a>pos_hi <span class="ot">&lt;-</span> dataBS<span class="sc">$</span>perPositive <span class="sc">+</span> (<span class="fl">1.96</span> <span class="sc">*</span> dataBS<span class="sc">$</span>PositiveSE)</span>
<span id="cb106-2"><a href="dictionaries.html#cb106-2" aria-hidden="true" tabindex="-1"></a>pos_lo <span class="ot">&lt;-</span> dataBS<span class="sc">$</span>perPositive <span class="sc">-</span> (<span class="fl">1.96</span> <span class="sc">*</span> dataBS<span class="sc">$</span>PositiveSE)</span>
<span id="cb106-3"><a href="dictionaries.html#cb106-3" aria-hidden="true" tabindex="-1"></a>neg_lo <span class="ot">&lt;-</span> dataBS<span class="sc">$</span>perNegative <span class="sc">-</span> (<span class="fl">1.96</span> <span class="sc">*</span> dataBS<span class="sc">$</span>NegativeSE)</span>
<span id="cb106-4"><a href="dictionaries.html#cb106-4" aria-hidden="true" tabindex="-1"></a>neg_hi <span class="ot">&lt;-</span> dataBS<span class="sc">$</span>perNegative <span class="sc">+</span> (<span class="fl">1.96</span> <span class="sc">*</span> dataBS<span class="sc">$</span>NegativeSE)</span>
<span id="cb106-5"><a href="dictionaries.html#cb106-5" aria-hidden="true" tabindex="-1"></a>dataBS <span class="ot">&lt;-</span> <span class="fu">cbind</span>(dataBS, pos_hi, pos_lo, neg_lo, neg_hi)</span></code></pre></div>
<p>Finally, we can then make the graph. Here, we plot each of the positive and negative points and then overlay them with their error bars:</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="dictionaries.html#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb107-2"><a href="dictionaries.html#cb107-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-3"><a href="dictionaries.html#cb107-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb107-4"><a href="dictionaries.html#cb107-4" aria-hidden="true" tabindex="-1"></a> <span class="fu">geom_point</span>(<span class="at">data =</span> dataBS,<span class="fu">aes</span>(<span class="at">x =</span> perPositive, <span class="at">y =</span> doc_id), <span class="at">shape =</span> <span class="dv">0</span>) <span class="sc">+</span></span>
<span id="cb107-5"><a href="dictionaries.html#cb107-5" aria-hidden="true" tabindex="-1"></a> <span class="fu">geom_point</span>(<span class="at">data =</span> dataBS,<span class="fu">aes</span>(<span class="at">x =</span> perNegative, <span class="at">y =</span> doc_id), <span class="at">shape =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb107-6"><a href="dictionaries.html#cb107-6" aria-hidden="true" tabindex="-1"></a> <span class="fu">geom_errorbarh</span>(<span class="at">data =</span> dataBS,<span class="fu">aes</span>(<span class="at">x =</span> perPositive, <span class="at">xmax =</span> pos_hi,<span class="at">xmin =</span> pos_lo, <span class="at">y =</span> doc_id)) <span class="sc">+</span></span>
<span id="cb107-7"><a href="dictionaries.html#cb107-7" aria-hidden="true" tabindex="-1"></a> <span class="fu">geom_errorbarh</span>(<span class="at">data =</span> dataBS,<span class="fu">aes</span>(<span class="at">x =</span> perNegative, <span class="at">xmax =</span> neg_hi,<span class="at">xmin =</span> neg_lo, <span class="at">y =</span> doc_id)) <span class="sc">+</span></span>
<span id="cb107-8"><a href="dictionaries.html#cb107-8" aria-hidden="true" tabindex="-1"></a> <span class="fu">xlab</span>(<span class="st">&quot;Percent positive/negative with 95% CIs&quot;</span>) <span class="sc">+</span></span>
<span id="cb107-9"><a href="dictionaries.html#cb107-9" aria-hidden="true" tabindex="-1"></a> <span class="fu">ylab</span>(<span class="st">&quot;review&quot;</span>)<span class="sc">+</span></span>
<span id="cb107-10"><a href="dictionaries.html#cb107-10" aria-hidden="true" tabindex="-1"></a> <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="Quantitative-Text-Analysis_files/figure-html/unnamed-chunk-76-1.png" width="672" /></p>
<p>As can be seen in this particular example, the fact that some documents are much less lengthier than others introduces a lot of uncertainty in the estimates. As evident from the overlapping confidence intervals in the figure, for most reviews, the percentage of negative words is not much different from the percentage of positive words. In other words: the sentiment for these reviews is rather mixed.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="reliability-and-validity.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="scaling.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Quantitative Text Analysis.pdf", "Quantitative Text Analysis.epub"],
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
